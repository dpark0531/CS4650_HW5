!pip install spacy
!pip install newsapi-python
!python -m spacy download en_core_web_lg

import spacy
import en_core_web_lg
nlp_eng = en_core_web_lg.load()

from newsapi.newsapi_client import NewsApiClient

newsapi = NewsApiClient (api_key='3c3d46dc7ac54e10bb26c117592d2cab')
articles=[]
for i in range (1,6):
  articles.append(newsapi.get_everything(q='coronavirus', language='en', from_param='2021-02-24', to='2021-03-23', sort_by='relevancy', page=i))

import pickle

filename = 'articlesCOVID.pckl'
pickle.dump(articles, open(filename, 'wb'))
filename = 'articlesCOVID.pckl'
loaded_model = pickle.load(open(filename, 'rb'))
filepath = '/content/articlesCOVID.pckl'
pickle.dump(loaded_model, open(filepath, 'wb'))

dados = []

import pandas as pd

for i, article in enumerate(articles):
    for x in article['articles']:
        title = x['title']
        date = x['publishedAt']
        description = x['description']
        content = x['content']
        dados.append({'title':title, 'publishedAt':date, 'desc':description, 'content':content})
df = pd.DataFrame(dados)
df = df.dropna()
df.head()


pos_tag = ["VERB", "NOUN", "PROPN"]
from string import punctuation
def get_keywords_eng(content):
  result = []
  doc = nlp_eng(content)
  for token in doc:
    if (token.text in nlp_eng.Defaults.stop_words or token.text in punctuation):
      continue
    if (token.pos_ in pos_tag):
       result.append(token.text)

  return result

from collections import Counter
results = []

for content in df.content.values:
    results.append([('#' + x[0]) for x in Counter(get_keywords_eng(content)).most_common(5)])
df['keywords'] = results

from wordcloud import WordCloud

import matplotlib.pyplot as plt

text = str(results)
wordcloud = WordCloud(max_font_size=50, max_words=100, background_color="white").generate(text)
plt.figure()
plt.imshow(wordcloud, interpolation="bilinear")
plt.axis("off")
plt.show()
